{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "import joblib\n",
        "\n",
        "# Load the dataset\n",
        "file_path = ('/content/aluminum_data_set_final.csv')\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# Extract numerical values from the Chemical Composition column\n",
        "def extract_composition(comp_str):\n",
        "    comp_dict = {}\n",
        "    components = comp_str.split(', ')\n",
        "    for comp in components:\n",
        "        element, percentage = comp.split(': ')\n",
        "        comp_dict[element.strip()] = float(percentage.strip('%'))\n",
        "    return comp_dict\n",
        "\n",
        "# Apply the extraction function to the Chemical Composition column\n",
        "composition_df = df['Chemical Composition'].apply(extract_composition).apply(pd.Series)\n",
        "\n",
        "# Concatenate the extracted composition features with the original dataset\n",
        "df_processed = pd.concat([df.drop(columns=['Chemical Composition']), composition_df], axis=1)\n",
        "\n",
        "# Convert the target 'Quality' column to binary (1 for Good, 0 for Bad)\n",
        "df_processed['Quality'] = df_processed['Quality'].apply(lambda x: 1 if x == 'Good' else 0)\n",
        "\n",
        "# Define features (X) and target (y)\n",
        "X = df_processed.drop(columns=['Quality'])\n",
        "y = df_processed['Quality']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Standardize the numerical features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Train a logistic regression model\n",
        "model = LogisticRegression(random_state=42)\n",
        "model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Evaluate the model\n",
        "y_pred = model.predict(X_test_scaled)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "class_report = classification_report(y_test, y_pred)\n",
        "\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "print(f\"Confusion Matrix:\\n{conf_matrix}\")\n",
        "print(f\"Classification Report:\\n{class_report}\")\n",
        "\n",
        "# Save the model and the scaler\n",
        "joblib.dump(model, 'aluminum_quality_model.pkl')\n",
        "joblib.dump(scaler, 'scaler.pkl')\n",
        "\n",
        "# Example prediction for new data input\n",
        "new_data = {\n",
        "    \"Casting Temperature (°C)\": 750,\n",
        "    \"Cooling Water Temperature (°C)\": 28,\n",
        "    \"Casting Speed (m/min)\": 1.5,\n",
        "    \"Cast Bar Entry Temperature at Rolling Mill (°C)\": 400,\n",
        "    \"Emulsion Temperature (°C)\": 60,\n",
        "    \"Pressure (MPa)\": 0.8,\n",
        "    \"Concentration (%)\": 5.5,\n",
        "    \"Rod Quench Water Pressure (MPa)\": 1.2,\n",
        "    \"Al\": 96.0,\n",
        "    \"Cu\": 1.0,\n",
        "    \"Si\": 0.8\n",
        "}\n",
        "\n",
        "# Convert the single input data to a DataFrame\n",
        "new_df = pd.DataFrame([new_data])\n",
        "\n",
        "# Scale the new input data using the saved scaler\n",
        "new_df_scaled = scaler.transform(new_df)\n",
        "\n",
        "# Make a prediction using the trained model\n",
        "prediction = model.predict(new_df_scaled)[0]\n",
        "prediction_label = \"Good\" if prediction == 1 else \"Not Good\"\n",
        "\n",
        "print(f\"Predicted Aluminum Quality: {prediction_label}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pFnRrzdWVclu",
        "outputId": "cb0b9293-8a14-4938-cf0f-e04f1f45ceac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.72\n",
            "Confusion Matrix:\n",
            "[[72  1]\n",
            " [27  0]]\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.73      0.99      0.84        73\n",
            "           1       0.00      0.00      0.00        27\n",
            "\n",
            "    accuracy                           0.72       100\n",
            "   macro avg       0.36      0.49      0.42       100\n",
            "weighted avg       0.53      0.72      0.61       100\n",
            "\n",
            "Predicted Aluminum Quality: Not Good\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for NaNs in the features and target\n",
        "print(df_processed.isna().sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xt5NhmkGdxpo",
        "outputId": "c59c0bce-75b8-401c-9bb4-272104ecf520"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Quality                                            0\n",
            "Casting Temperature (°C)                           0\n",
            "Cooling Water Temperature (°C)                     0\n",
            "Casting Speed (m/min)                              0\n",
            "Cast Bar Entry Temperature at Rolling Mill (°C)    0\n",
            "Emulsion Temperature (°C)                          0\n",
            "Pressure (MPa)                                     0\n",
            "Concentration (%)                                  0\n",
            "Rod Quench Water Pressure (MPa)                    0\n",
            "Al                                                 0\n",
            "Cu                                                 0\n",
            "Si                                                 0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove rows with NaN values from both X and y\n",
        "df_processed = df_processed.dropna()\n",
        "X = df_processed.drop(columns=['Quality'])\n",
        "y = df_processed['Quality']"
      ],
      "metadata": {
        "id": "zMPeqyMBd2ob"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "IKNHsfQXd5NI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for NaNs in y_train and y_test\n",
        "print(pd.Series(y_train).isna().sum())\n",
        "print(pd.Series(y_test).isna().sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "loapMtfvd8gY",
        "outputId": "c7aaba39-b66c-4735-f10f-28ed30fd885d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Standardize the numerical features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Train the logistic regression model\n",
        "model = LogisticRegression(random_state=42, multi_class='ovr')\n",
        "model.fit(X_train_scaled, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "1Oud8drcd-8V",
        "outputId": "efeecce4-865e-46b3-c893-790bc74a0e1c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(multi_class='ovr', random_state=42)"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(multi_class=&#x27;ovr&#x27;, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(multi_class=&#x27;ovr&#x27;, random_state=42)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "import joblib\n",
        "\n",
        "# Load the dataset\n",
        "file_path = '/content/aluminum_data_set_final.csv'\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# Extract numerical values from the Chemical Composition column\n",
        "def extract_composition(comp_str):\n",
        "    comp_dict = {}\n",
        "    components = comp_str.split(', ')\n",
        "    for comp in components:\n",
        "        element, percentage = comp.split(': ')\n",
        "        comp_dict[element.strip()] = float(percentage.strip('%'))\n",
        "    return comp_dict\n",
        "\n",
        "# Apply the extraction function to the Chemical Composition column\n",
        "composition_df = df['Chemical Composition'].apply(extract_composition).apply(pd.Series)\n",
        "\n",
        "# Concatenate the extracted composition features with the original dataset\n",
        "df_processed = pd.concat([df.drop(columns=['Chemical Composition']), composition_df], axis=1)\n",
        "\n",
        "# Map 'Quality' column to three classes (Good: 2, Moderate: 1, Not Good: 0)\n",
        "df_processed['Quality'] = df_processed['Quality'].map({'Good': 2, 'Moderate': 1, 'Not Good': 0})\n",
        "\n",
        "# Remove rows with NaN values\n",
        "df_processed = df_processed.dropna()\n",
        "\n",
        "# Define features (X) and target (y)\n",
        "X = df_processed.drop(columns=['Quality'])\n",
        "y = df_processed['Quality']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Standardize the numerical features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Train a logistic regression model\n",
        "model = LogisticRegression(random_state=42, multi_class='ovr')\n",
        "model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Evaluate the model\n",
        "y_pred = model.predict(X_test_scaled)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "# Check unique labels in y_test and y_pred\n",
        "print(\"Unique labels in y_test:\", y_test.unique())\n",
        "print(\"Unique labels in y_pred:\", set(y_pred))\n",
        "\n",
        "# Define target names based on unique labels\n",
        "labels = sorted(set(y_test) | set(y_pred))\n",
        "label_names = {0: 'Not Good', 1: 'Moderate', 2: 'Good'}\n",
        "target_names = [label_names[label] for label in labels]\n",
        "\n",
        "# Generate the classification report\n",
        "class_report = classification_report(y_test, y_pred, target_names=target_names)\n",
        "\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "print(f\"Confusion Matrix:\\n{conf_matrix}\")\n",
        "print(f\"Classification Report:\\n{class_report}\")\n",
        "\n",
        "# Save the model and the scaler\n",
        "joblib.dump(model, 'aluminum_quality_model.pkl')\n",
        "joblib.dump(scaler, 'scaler.pkl')\n",
        "\n",
        "# Now, let's use the trained model to make predictions based on manual input\n",
        "\n",
        "# Load the saved model and scaler\n",
        "loaded_model = joblib.load('aluminum_quality_model.pkl')\n",
        "loaded_scaler = joblib.load('scaler.pkl')\n",
        "\n",
        "# Manually input values\n",
        "al = float(input(\"Enter Aluminum Content (%): \"))\n",
        "cu = float(input(\"Enter Copper Content (%): \"))\n",
        "si = float(input(\"Enter Silicon Content (%): \"))\n",
        "casting_temp = float(input(\"Enter Casting Temperature (°C): \"))\n",
        "cooling_water_temp = float(input(\"Enter Cooling Water Temperature (°C): \"))\n",
        "casting_speed = float(input(\"Enter Casting Speed (m/min): \"))\n",
        "bar_entry_temp = float(input(\"Enter Cast Bar Entry Temperature at Rolling Mill (°C): \"))\n",
        "emulsion_temp = float(input(\"Enter Emulsion Temperature (°C): \"))\n",
        "pressure = float(input(\"Enter Pressure (MPa): \"))\n",
        "concentration = float(input(\"Enter Concentration (%): \"))\n",
        "rod_quench_pressure = float(input(\"Enter Rod Quench Water Pressure (MPa): \"))\n",
        "\n",
        "# Create a single input data dictionary with the same feature order as in training\n",
        "input_data = {\n",
        "    \"Al\": al,\n",
        "    \"Cu\": cu,\n",
        "    \"Si\": si,\n",
        "    \"Casting Temperature (°C)\": casting_temp,\n",
        "    \"Cooling Water Temperature (°C)\": cooling_water_temp,\n",
        "    \"Casting Speed (m/min)\": casting_speed,\n",
        "    \"Cast Bar Entry Temperature at Rolling Mill (°C)\": bar_entry_temp,\n",
        "    \"Emulsion Temperature (°C)\": emulsion_temp,\n",
        "    \"Pressure (MPa)\": pressure,\n",
        "    \"Concentration (%)\": concentration,\n",
        "    \"Rod Quench Water Pressure (MPa)\": rod_quench_pressure,\n",
        "}\n",
        "\n",
        "# Convert the input data to a DataFrame with the correct order of columns\n",
        "input_df = pd.DataFrame([input_data], columns=X.columns)\n",
        "\n",
        "# Scale the input data using the loaded scaler\n",
        "input_scaled = loaded_scaler.transform(input_df)\n",
        "\n",
        "# Make a prediction using the loaded model\n",
        "prediction = loaded_model.predict(input_scaled)[0]\n",
        "prediction_label = {2: \"Good\", 1: \"Moderate\", 0: \"Not Good\"}[prediction]\n",
        "\n",
        "print(f\"Predicted Aluminum Quality: {prediction_label}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k3Vw_aSXeBnW",
        "outputId": "d3373410-a767-4c6c-ecec-9f4d063e847d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unique labels in y_test: [2. 1.]\n",
            "Unique labels in y_pred: {1.0, 2.0}\n",
            "Accuracy: 0.47761194029850745\n",
            "Confusion Matrix:\n",
            "[[11 28]\n",
            " [ 7 21]]\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    Moderate       0.61      0.28      0.39        39\n",
            "        Good       0.43      0.75      0.55        28\n",
            "\n",
            "    accuracy                           0.48        67\n",
            "   macro avg       0.52      0.52      0.47        67\n",
            "weighted avg       0.53      0.48      0.45        67\n",
            "\n",
            "Enter Aluminum Content (%): 54\n",
            "Enter Copper Content (%): 115\n",
            "Enter Silicon Content (%): 121\n",
            "Enter Casting Temperature (°C): 788\n",
            "Enter Cooling Water Temperature (°C): 145\n",
            "Enter Casting Speed (m/min): 111\n",
            "Enter Cast Bar Entry Temperature at Rolling Mill (°C): 4444\n",
            "Enter Emulsion Temperature (°C): 555\n",
            "Enter Pressure (MPa): 11\n",
            "Enter Concentration (%): 11\n",
            "Enter Rod Quench Water Pressure (MPa): 11\n",
            "Predicted Aluminum Quality: Good\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "2nG6HSqtaHt2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "from sklearn.ensemble import RandomForestClassifier  # Example model\n",
        "\n",
        "# Train your model (replace with your actual training code)\n",
        "model = RandomForestClassifier()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Save the trained model\n",
        "joblib.dump(model, 'model.pkl')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K8XAhmvWscO0",
        "outputId": "4cb322d7-486d-4e67-9279-f01763cb7eaa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['model.pkl']"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python train_model.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AnOVSqdlskLi",
        "outputId": "b6dc16d1-da9a-499b-cbb1-059ec9a1c4ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "python3: can't open file '/content/train_model.py': [Errno 2] No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "from sklearn.ensemble import RandomForestClassifier  # Example model\n",
        "\n",
        "# Train your model (replace with your actual training code)\n",
        "model = RandomForestClassifier(random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Save the trained model\n",
        "joblib.dump(model, 'model.pkl')\n",
        "\n",
        "# Save the scaler as well\n",
        "joblib.dump(scaler, 'scaler.pkl')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n781sYBTn6Vq",
        "outputId": "aea063f7-abad-4347-d971-c70008cff39f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['scaler.pkl']"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "import pandas as pd\n",
        "\n",
        "# Load the saved model and scaler\n",
        "loaded_model = joblib.load('model.pkl')\n",
        "loaded_scaler = joblib.load('scaler.pkl')\n",
        "\n",
        "# Manually input values (this would typically come from user input or a form)\n",
        "input_data = {\n",
        "    \"Al\": al,\n",
        "    \"Cu\": cu,\n",
        "    \"Si\": si,\n",
        "    \"Casting Temperature (°C)\": casting_temp,\n",
        "    \"Cooling Water Temperature (°C)\": cooling_water_temp,\n",
        "    \"Casting Speed (m/min)\": casting_speed,\n",
        "    \"Cast Bar Entry Temperature at Rolling Mill (°C)\": bar_entry_temp,\n",
        "    \"Emulsion Temperature (°C)\": emulsion_temp,\n",
        "    \"Pressure (MPa)\": pressure,\n",
        "    \"Concentration (%)\": concentration,\n",
        "    \"Rod Quench Water Pressure (MPa)\": rod_quench_pressure,\n",
        "}\n",
        "\n",
        "# Convert the input data to a DataFrame with the correct order of columns\n",
        "input_df = pd.DataFrame([input_data], columns=X.columns)\n",
        "\n",
        "# Scale the input data using the loaded scaler\n",
        "input_scaled = loaded_scaler.transform(input_df)\n",
        "\n",
        "# Make a prediction using the loaded model\n",
        "prediction = loaded_model.predict(input_scaled)[0]\n",
        "prediction_label = {2: \"Good\", 1: \"Moderate\", 0: \"Not Good\"}[prediction]\n",
        "\n",
        "print(f\"Predicted Aluminum Quality: {prediction_label}\")\n"
      ],
      "metadata": {
        "id": "-a3s1MaQoo-0",
        "outputId": "705fe95c-235c-4403-f437-4a62eadb0b0b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted Aluminum Quality: Not Good\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    }
  ]
}